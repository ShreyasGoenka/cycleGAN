{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device being used:  cpu\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from cycle_gan import CycleGAN\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "x = CycleGAN()\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
    "image = torch.zeros(2048)\n",
    "writer.add_graph(x.netG_A, image)\n",
    "writer.close()\n",
    "\n",
    "dataA = np.genfromtxt('./office31_features/amazon_amazon.csv', delimiter=',')\n",
    "featuresA = dataA[:,:2048]\n",
    "labelsA = dataA[:,2048]\n",
    "\n",
    "dataB = np.genfromtxt('./office31_features/amazon_dslr.csv', delimiter=',')\n",
    "featuresB = dataB[:,:2048]\n",
    "labelsB = dataB[:,2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "featuresA0 = []\n",
    "featuresB0 = []\n",
    "featuresA1 = []\n",
    "featuresB1 = []\n",
    "\n",
    "for i in range(0,dataA.shape[0]):\n",
    "    if (labelsA[i] == 0.0):\n",
    "        featuresA0.append(featuresA[i])\n",
    "#         print(dataA[i][-1])\n",
    "    if (labelsA[i] == 1.0):\n",
    "        featuresA1.append(featuresA[i])\n",
    "#         print(dataA[i][-1])\n",
    "        \n",
    "print(\"-------------------------\")\n",
    "        \n",
    "for i in range(0, dataB.shape[0]):\n",
    "    if (labelsB[i] == 0.0):\n",
    "        featuresB0.append(featuresB[i])\n",
    "#         print(dataB[i][-1])\n",
    "    if (labelsB[i] == 1.0):\n",
    "        featuresB1.append(featuresB[i])\n",
    "#         print(dataB[i][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 82 12 21\n"
     ]
    }
   ],
   "source": [
    "print(len(featuresA0), len(featuresA1), len(featuresB0), len(featuresB1))\n",
    "labelsA0 = np.zeros(len(featuresA0))\n",
    "labelsA1 = np.ones(len(featuresA1))\n",
    "labelsB0 = 2*np.ones(len(featuresB0))\n",
    "labelsB1 = 2*np.ones(len(featuresB1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(featuresA, labelsA)\n",
    "\n",
    "imagesx, labelsx = select_n_random(featuresB, labelsB)\n",
    "\n",
    "# log embeddings\n",
    "writer.add_embedding(images,\n",
    "                    metadata=labels, tag = 'amazon')\n",
    "writer.add_embedding(imagesx, metadata=labelsx+31, tag = 'dslr')\n",
    "\n",
    "writer.add_embedding(np.concatenate((images,imagesx)), metadata = np.concatenate((np.zeros(100), np.ones(100))), tag = 'both domains')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "W0215 02:06:32.303692 140287008540416 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0215 02:06:32.304440 140287008540416 plugin_event_accumulator.py:322] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W0215 02:06:32.307765 140287008540416 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0215 02:06:32.308198 140287008540416 plugin_event_accumulator.py:322] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W0215 02:06:32.311882 140287008540416 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0215 02:06:32.312364 140287008540416 plugin_event_accumulator.py:322] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W0215 02:06:32.318074 140287008540416 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0215 02:06:32.318720 140287008540416 plugin_event_accumulator.py:322] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W0215 02:06:32.323362 140287008540416 plugin_event_accumulator.py:294] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W0215 02:06:32.323727 140287008540416 plugin_event_accumulator.py:322] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.1.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
